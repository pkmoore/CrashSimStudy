\section{Introduction}
\label{SEC:introduction}
\textit{No Battle Plan Survives Contact With the Enemy --- Helmuth von Moltke}

No matter how well an application is tested before being released,
new bugs always seem emerge after deployment.
One reason is that these applications will run in a diverse set of
deployment \emph{environments},
and variations between these environments tend to
reveal previously undiscovered flaws.
APIs provided by operating systems can change across versions~\cite{LinuxGlibcChanges},
file systems can exhibit subtle but critical differences~\cite{EXT4Layout, AppleHFS},
and, even if the network and adapter are identical,
network behavior can still diverge from what is expected~\cite{vbox}.
These environmental differences greatly exacerbate
the chance that an application will function incorrectly when deployed.

These unforeseeable environmental bugs
complicate the work of application developers who, according to a
recent survey conducted by ClusterHQ~\cite{ClusterHQSurvey},
spend a significant portion of their time
debugging errors that only appear in production.
% Participants in this survey cited the inability to recreate
% production environments for
% testing as the main reason why bugs are not discovered earlier.
Efforts have been made in several directions to reduce this burden.  One
approach is to hide environmental differences behind standard interfaces.
Unfortunately,
even specialized ``Write-Once, Run Anywhere'' environments
that attempt to hide these environmental differences,
such as the Java Runtime Environment,
are not perfect,
leading them to be rechristened ``Write-Once, Debug Everywhere''~\cite{WODE}.
A more direct approach is
to identify and fix deficiencies before deployment
but history has shown that,
even if enormous developer effort is put forward,
it may be insufficient to uncover these bugs.
Microsoft employs thousands of engineers with nearly a
1:1 ratio of testers to developers~\cite{Page2009}.
Yet, a recent Windows Update released
in response to the Spectre Intel CPU vulnerability
resulted in machines with certain hardware configurations
being rendered unbootable~\cite{kb4056892}.


The work documented in this paper
hopes to move the needle in the developer's favor
by presenting a new technique for catching environmental bugs
so expensive and time consuming post-deployment fixes can be avoided.
Guiding our efforts
is a technique
we call \textit{results based simulation}.
It is founded upon the key insight
that problematic environmental properties
(which we refer to as \textit{anomalies})
are visible in the communications
between application and its environment.
When employing \textit{results based simulation},
the anomalies that represent a given environment
are identified by
observing applications already running within the environment
as they communicate with it
through function calls,
system calls,
or similar means.
Other applications can be tested in an simulation of that environment
by intercepting it's communications
and modifying them in such a way
the observed anomalies present.
The way the application responds to the simulated anomalies
indicates the potential for bugs once the it is actually deployed
to the target environment.

To test the ability of this technique to expose environmental
bugs, we built and tested a proof of concept tool
called {\em CrashSimulator}\footnote{Our approach is
loosely inspired by flight simulators, which test pilot aptitude under a
variety of rare, adverse scenarios (water landings, engine failures, etc.)
before the pilots are certified to work in practice.}.
{\em CrashSimulator} implements \textit{results based simulation}
by intercepting and manipulating the results and side-effects
of the system calls an application makes.
% These operations are performed with the help of a novel strategy
% called \textit{process set cloning} which allows numerous clones of an
% application's processes to be generated during the course of execution so
% destructive tests do not necessitate a full re-execution.
Our results showed that the tool was able to find bugs,
both known and unknown,
in Linux applications ranked highly on Debian's popularity
contest~\cite{DebPopCon}.  The applications were exposed to
environmental conditions present as a result of unanticipated
file system configurations, file types, and network delays.
When the applications in
question were actually exposed to these conditions a variety of failures
including hangs, crashes, and filesystem damage occurred.  In total,
\textbf{!!!!RECOUNT!!!!} 84
bugs were identified in this manner.

In addition to proving CrashSimulator could find bugs, we were also able to
show that developers with varying backgrounds
could use the tool to identify bugs
in real world applications
with a high degree of confidence.
We conducted a user study with
ZZZ Undergraduate and Graduate computer science students
who were asked to use CrashSimulator to test
the same type of applications evaluated in our initial tests.
The results show that the developers were able to find bugs
that were missed by the applications' existing testing strategies.
Additionally, the
participants were able to find bugs
in environments with which they had a limited amount of experience.

\preston{I kept contribution 1 because I think we make this case pretty
strongly in section II.}

The main contributions in this work can be summarized as follows:

\begin{enumerate}

\item{It provides evidence
that previously unanticipated flaws can be created by the interaction
between an application and its environment.}

\item{It introduces \textit{Results Based Simulation}
as an easy-to-use method of simulating environments
so an applications' behavior in those environments
can be assessed before deployment
without the time and resource costs of
testing each environment individually.}

\item{It demonstrates a new tool, {\em CrashSimulator},
which implements results based simulation
in order to find previously-undiscovered environmental bugs
in widely deployed and highly tested code.}

\item{It shows that developers are able
to use {\em CrashSimulator}
to find real bugs in real applications.}

\end{enumerate}
