\section{Introduction}
\label{SEC:introduction}
\textit{No Battle Plan Survives Contact With the Enemy --- Helmuth von Moltke}

No matter how well an application is tested before being released,
new bugs always seem emerge after deployment.
One reason is that these applications will operate within a diverse set of
deployment \emph{environments},
and variations between these environments tend to
reveal previously undiscovered flaws.
These flaws emerge from environmental differences
caused by such factors as
operating system APIs changing across versions
~\cite{LinuxGlibcChanges},
or small variations in file systems exhibiting subtle but critical
differences~\cite{EXT4Layout, AppleHFS}.
Even if the network and adapter are identical,
network behavior can still diverge from what is expected~\cite{vbox}.
These environmental differences greatly exacerbate
the chance that an application will function incorrectly when deployed.

These unforeseeable environmental bugs
complicate the work of application developers who, according to a
recent survey conducted by ClusterHQ~\cite{ClusterHQSurvey},
spend a significant portion of their time
debugging errors that only appear in production.
% Participants in this survey cited the inability to recreate
% production environments for
% testing as the main reason why bugs are not discovered earlier.
Numerous efforts have been made to reduce this burden.
One approach
is to hide environmental differences behind standard interfaces.
Unfortunately,
even specialized ``Write-Once, Run Anywhere'' environments
that attempt to hide these differences,
such as the Java Runtime Environment,
are not perfect,
leading them to be rechristened ``Write-Once, Debug Everywhere''~\cite{WODE}.
A more direct approach is
to identify and fix deficiencies before deployment,
but history has shown that,
even if enormous developer effort is put forward,
it may be insufficient to uncover these bugs.
Microsoft employs thousands of engineers with nearly a
1:1 ratio of testers to developers~\cite{Page2009}.
Yet, a recent Windows Update released
in response to the Spectre Intel CPU vulnerability
resulted in machines with certain hardware configurations
being rendered unbootable~\cite{kb4056892}.


The work documented in this paper
seeks to move the needle in the developer's favor
by presenting a new technique for catching environmental bugs
so expensive and time consuming post-deployment fixes can be avoided.
Guiding our efforts
is a technique
we call \textit{Anomalous Environment Simulation} (AES).
It is founded upon the key insight
that problematic environmental properties
(which we refer to as \textit{anomalies})
can be detected in the communications
between an application and its environment.
When employing AES,
the anomalies in a given environment
are identified by
observing results from the communications of other applications.
That is,
the function calls,
system calls,
or other communications an application makes in an environment provide
a record of probable issues.
The communications of the application being tested can be intercepted
and modified in such a way
that the observed anomalies are present.
Then, the way the application responds to the simulated anomalies
will indicate any potential for bugs upon deployment
within the target environment.

To verify the ability of this technique to reveal environmental
bugs, we built and tested a proof of concept tool
called {\em CrashSimulator}\footnote{Our approach is
loosely inspired by flight simulators, which test pilot aptitude under a
variety of rare, adverse scenarios (water landings, engine failures, etc.)
before the pilots are certified to work in practice.}.
Our results showed that the tool was able to find bugs,
both known and unknown,
in Linux applications ranked highly on Debian's popularity
contest~\cite{DebPopCon}.  The applications were exposed to
environmental conditions present as a result of unanticipated
file system configurations, file types, and network delays.
When the applications in
question were actually exposed to these conditions a variety of failures
including hangs, crashes, and filesystem damage occurred.  In total,
\textbf{!!!!RECOUNT!!!!} 84
bugs were identified in this manner.

In addition to proving CrashSimulator could find bugs, we were also able to
show that developers with varying backgrounds
could use the tool
on real world applications
with a high degree of confidence.
We conducted a user study with
ZZZ undergraduate and graduate computer science students
who were asked to use CrashSimulator to test
the same type of applications evaluated in our initial tests.
The results show that the developers were able to find bugs
that were missed by the applications' existing testing strategies.
Additionally, the
participants were able to find bugs
in environments with which they had only a limited amount of experience.

\preston{I kept contribution 1 because I think we make this case pretty
strongly in section II.}

The main contributions in this work can be summarized as follows:

\begin{enumerate}

\item{It provides evidence
that previously unanticipated flaws can be created by the interaction
between an application and its environment.}

\item{It introduces \textit{Anomalous Environment Simulation}
as an easy-to-use method of simulating environments
so an application's behavior in those environments
can be assessed before deployment---
without the time and resource costs of
testing each environment individually.}

\item{It demonstrates a new tool, {\em CrashSimulator},
which implements anomalous environment simulation
in order to find previously-undiscovered environmental bugs
in widely deployed and highly tested code.}

\item{It proves the effectiveness
of {\em CrashSimulator}
by presenting results
in which developers
were able to find real bugs in real applications.}

\end{enumerate}
