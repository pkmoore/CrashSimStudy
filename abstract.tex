\begin{abstract}

A common problem for software developers is that applications exhibit new
bugs after they have been deployed as a result of unanticipated
differences between its development and deployment environments.  When
factors such as new OS versions, file systems and network middleboxes
present themselves they can cause an application to crash or fail.  To
this point, avoiding such behavior has proven difficult because it is
not feasible to test against all the potential environments an
application might face.

Enter CrashSimulator, a tool that uses information about how environments
differ to identify incorrect behavior before the application is
deployed.  The tool modifies system call return values and side effects
to simulate an anomalous environment and makes a determination about
whether or not the application is responding correctly to it.  As
unusual environmental properties are encoded as differences in system
call behavior, CrashSimulator can use incorrect behavior identified in
one application running in one environment to determine whether other
applications would make the same mistake in that environment.

We evaluated CrashSimulator by using it to test a set of the most popular
Linux applications selected
from the Coreutils project and the Debian popularity contest. The
result of this evaluation was 84 bugs identified in 31 applications
with consequences ranging from hangs and crashes to data loss and
remote denial of service conditions.  We also compared CrashSimulator
to two similar tools (AFL and Mutiny) in a
study in which ZZZ participants used the tools to
hunt for bugs in popular applications.  This study revealed
that CrashSimulator's strategy of identifying bugs
is effective, and yielded results for
developers with diverse backgrounds, and across skill sets.
As YYY novel bugs were identified and reported during the study,
CrashSimulator is poised to help uncover a
great deal of previously unidentified bugs in new and existing
codebases.

\end{abstract}
