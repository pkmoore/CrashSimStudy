\section{Defining and Applying the Results Based Simulation Technique}
\label{SEC:approach}

\begin{figure}[t]
  \center{}
  \fbox{\includegraphics[scale=.37]{images/approach}}
  \caption{Diagram illustrating CrashSimulator's approach}
  \label{figure:approach}
\end{figure}

\begin{figure*}[t]
  \center{}
  \fbox{\includegraphics[scale=.65]{images/architecture}}
  \caption{Diagram illustrating CrashSimulator's Architecture.  During the
    course of a single rr execution, clone process sets are generated at
    specific rr events.  A CrashSimlator supervisor process attaches to
    these process sets and uses a strace-style system call listing to feed
    subsequent system call activity and inject unusual environmental
    conditions.}
  \label{figure:architecture}
\end{figure*}

As mentioned earlier,
the Results Based Simulation (RBS) technique
offers a reliable way to identify bugs
that could arise from interaction with a given environment.
In this section,
we will break down the elements of the technique,
and then introduce a tool called CrashSimulator,
which we built as a concrete implementation of RBS.
We also describe a second technology
called Process Set Cloning
that evolved during our work on CrashSimulator.


\subsection{Stepping through RBS}

The first step in implementing RBS
is selecting an anomaly or anomalies
against which you wish to test applications.
Anomalies can be collected
by examining failures of other applications
in a target deployment environment,
exploring public bug trackers,
or by using tools that can identify
potentially problematic environmental conditions~\cite{Zhuang_NSDI_2014,
rasley2015detecting}.
Identifying anomalies through bugs posted on public trackers
is ideal when determining
whether or not an application
is vulnerable to a widely publicized bug.
The chosen anomalies are then examined
in order to determine how they cause an application's communications
with its environment
to differ from a normal execution.
Once they have been teased out,
these differences can be represented
as a set of modifications
that must be made to an application's communications
in order to simulate the chosen anomaly or anomalies.
As an example,
consider an anomalous environment
where access to a required file is denied because of
the environment's configured file permissions.
This anomaly presents as attempts to access the file,
such as calls to {\tt fread()},
the {\tt read()} system call,
or other file access mechanisms,
returning an error stating that access to the file is denied.
The ``modification'' required to simulate this anomaly
is to change the results of similar accesses
in a test execution
to return ``access denied.''

The second step
is identifying
a way to monitor an application's communication
with its environment,
by redirecting function calls,
observing memory access,
monitoring network activity,
intercepting system calls,
or some other similar means.
These opportunities are identified by looking at the parameters,
return values,
and orderings,
of an application's communications
that indicate
it is an appropriate time to simulate an anomaly.
Monitoring an application's communications
in this fashion
has the added benefit
of allowing us to find obvious situations
where an application will fail
to handle certain environmental features.
This is possible because an application's failure
to carry out required operations is visible as it interacts
with its environment.
Consider an application that fails to check whether or not
a file already exists
before destructively opening it and writing to it.
The absence of this check
is problematic in environments where the file already exists
as it will be blindly overwritten.
Because it is obvious from the sequence of communications
the application makes when writing to the file
that this check has been neglected,
no simulation is required to identify the presence of a bug.

The third step in RBS
involves interposing on communications
and making the modifications necessary
to simulate the presence
of an environmental anomaly.
This could be accomplished by
influencing the results of function calls,
strategically altering memory values,
altering the results of system calls,
or some other method
of presenting modified communications to an application.
In the simplest case,
simulating an anomaly only requires
the modification of a single value.
In more complex cases,
large numbers of diverse communications
need to be interdicted and altered
in order to correctly simulate an anomaly.
For example,
simulating an erratic system clock
requires that all efforts
to access the clock
be correctly modified
to reflect the chosen aberration.

Lastly, the fourth RBS step
is to analyze an application's response
to a simulated anomaly.
This is accomplished by evaluating an application's
communications after it has been exposed
to a simulated anomaly.
The simplest conclusion to draw
is whether or not the application
has made an effort to respond
to the anomaly.
This determination can be made based
on the assumption that the way an
application deals with the anomaly will yield
different program paths (and therefore different communications) than
it would execute absent the anomaly.
If the application
does not alter its behavior, it has not
correctly handled this flaw --- a failing result.
Alternatively,
if the application does deviate,
it is likely that the application is taking some
action to handle the injected condition --- an indication of possibly
correct behavior.
This approach is often sufficient
to classify application behavior.
As with traditional tests,
CrashSimulator does not tell us that an application
is bug free in a given situation;
instead,
it asserts that an application
has incorrectly handled a given situation.

A limitation of the above strategy
is that it can result in false negatives
when application's change their behavior
but do not handle the anomaly correctly.
These false negatives can be addressed
by more detailed analysis
of the application's post simulation behavior.
This more detailed analysis
depends upon knowing what a correct response
to an anomaly looks like.
This ``known good'' behavior can be found
in a number of ways
including by looking at standards and documentation
that describe best practices for handling an anomaly
in a given environment
and examining how applications that correctly
deal with the anomaly do so.
Consider the case where the system call {\tt close()} fails.
Whether or not retrying the call is correct
depends upon what environment is being simulated.
Instead, the application's post-simulation communications
must be examined in enough detail to identify a repeated {\tt close()}
call taking into account
what is correct for the environment being simulated.

\subsection{CrashSimulator: A Concrete RBS Implementation}

Evaluating RBS in a real-world fashion
requires a concrete implementation of its four components.
We built this implementation
into a tool we call CrashSimulator,
the details of which are described below.

The first decision made was to implement RBS by manipulating an
applications communications at the system call level.
Operating at this level provides a few key
advantages.  First, there is already robust tooling in the Linux kernel
that allows for the interception and modification of system call results
and side effects.  Additionally, Linux system call semantics are well
defined which simplifies implementation.  Finally, operating at this level
allows CrashSimulator to test applications written any language that can
execute Linux system calls.

Work then turned to gathering a corpus of anomalies to test applications
against.  These anomalies (which are further discussed
in~\ref{SEC:evaluation}) were collected by examining public bug trackers,
the source code of major portable applications, and the capabilities of
tools like NetCheck~\cite{Zhuang_NSDI_2014}
and CheckAPI~\cite{rasley2015detecting}.  These anomalies were converted
into sets of modifications that simulate the presence of an anomaly when
appropriately applied to the results of the system calls an application
makes.
This process required manual effort and expertise.  However,
much like
the effort involved in constructing a unit test to check for correct
behavior in a piece of code, this initial outlay of
user skill and effort will be paid back, as it is
used repeatedly over time to test many different applications.

The second step of RBS, communication monitoring, was achieved by
application executions using a modified version of the {\tt rr}!!CITE!!
record-and-replay debugger.  The specific modification that allowed this
capability was an enhancement we made that resulted in {\tt strace} style
system call recording being output alongside {\tt rr's} normal recording
format.
This enhancement provided
a complete log of an applications system call activity
that could be used to identify opportunities to simulate anomalies.  As was
discussed earlier, simply observing these system calls was enough to
identify bugs-of-omission in many applications.  This is discussed further
in~\ref{SEC:evaluation}.

Anomaly simulation is implemented in CrashSimulator using a novel technique
referred to as {\tt process set cloning}.  This technique uses the second
modification we made to rr -- the ability to generate copies of the set of
processes underlying an application at opportune moments during replay.
{\tt rr} manages
the full set of processes an application requires and offers the ability to
make a copy of it so that users can test debugging
hypotheses without damaging the originals.  Our modified version of {\tt
rr} extends this capability to allow process sets to be liberated from {\tt
rr} so that they can be exposed to simulated anomalies.
This means that we can rely on {\tt rr}
to store the information necessary to perform the bulk of
replay that must take place before the application reaches the point in
execution where testing will be performed.  When this point is reached we
take advantage of these combined capabilities
to create a
copy of the set of processes being replayed and liberate them so our
CrashSimulator process supervisor can take over replay responsibilities.

Process sets generated by {\tt rr} are created in a stopped state and
remain until they are attached to and utilized by a CrashSimulator
supervisor.  Each process set has its own supervisor process to inject
its configured environmental anomaly.  The
supervisor wakes up the process set it is managing and simulates any
subsequent system calls it makes.  The data necessary for this
simulation is
supplied as a system call listing formatted after the style of {\tt strace}
output, that describes the results and side effects for each system
call. The output is engineered in such a way to contain the
elements required to reflect the
desired environmental anomaly.  Supervisors can complete this
process independently of one another, which lends a
high degree of speed and
parallelism to the whole CrashSimulator testing process.


